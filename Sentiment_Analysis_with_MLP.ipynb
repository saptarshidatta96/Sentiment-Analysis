{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcldsd7tt+016Hs0AwS21W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/Sentiment-Analysis/blob/main/Sentiment_Analysis_with_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KafekGRuQomu"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-NQWvkoQ34k",
        "outputId": "84ed4141-0124-49d4-d8a0-2736ca6405ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TKnCYcSESs"
      },
      "source": [
        "!tar -xvf \"/content/gdrive/MyDrive/aclImdb_v1.tar.gz\" -C \"/content/\"  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM8uU5iclDjN"
      },
      "source": [
        "def load_dataset(dataset):\n",
        "  data = []\n",
        "  label = []\n",
        "  for item in os.listdir('/content/aclImdb/{}/'.format(dataset)):\n",
        "    if item == 'pos':\n",
        "      tweet_txt = os.path.join('/content/aclImdb/{}/'.format(dataset), item)\n",
        "      for tweets in os.listdir(tweet_txt):\n",
        "        if tweets.endswith('.txt'):\n",
        "          with open(os.path.join(tweet_txt, tweets)) as f:\n",
        "            data.append(f.read())\n",
        "          label.append(1)\n",
        "\n",
        "    elif item == 'neg':\n",
        "      tweet_txt = os.path.join('/content/aclImdb/{}/'.format(dataset), item)\n",
        "      for tweets in os.listdir(tweet_txt):\n",
        "        if tweets.endswith('.txt'):\n",
        "          with open(os.path.join(tweet_txt, tweets)) as f:\n",
        "            data.append(f.read())\n",
        "          label.append(0)\n",
        "\n",
        "  return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3tzN97duDLz"
      },
      "source": [
        "train_data, train_label = load_dataset('train')\n",
        "test_data, test_label = load_dataset('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-EMJP161_A0"
      },
      "source": [
        "random.seed(42)\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL_Cp6wFx0j3"
      },
      "source": [
        "def split_training_and_validation_sets(data, label, validation_split):\n",
        "\n",
        "    num_training_samples = int((1 - validation_split) * len(data))\n",
        "    return ((data[:num_training_samples], label[:num_training_samples]),\n",
        "            (data[num_training_samples:], label[num_training_samples:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0b7fhSEMq1"
      },
      "source": [
        "(train_data, train_label), (valid_data, valid_label) = split_training_and_validation_sets(train_data, train_label, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOhEu_8Qb-lT"
      },
      "source": [
        "def ngram_vectorizer(train_data, train_label, valid_data):\n",
        "\n",
        "    kwargs = {\n",
        "            'ngram_range': (1, 2), \n",
        "            'dtype': 'int32',\n",
        "            'strip_accents': 'unicode',\n",
        "            'decode_error': 'replace',\n",
        "            'analyzer': 'word', \n",
        "            'min_df': 2,\n",
        "    }\n",
        "    vectorizer = TfidfVectorizer(**kwargs)\n",
        "\n",
        "    train_data = [str (item) for item in train_data]\n",
        "    valid_data = [str (item) for item in valid_data]\n",
        "\n",
        "    x_train = vectorizer.fit_transform(train_data)\n",
        "\n",
        "    x_val = vectorizer.transform(valid_data)\n",
        "\n",
        "    selector = SelectKBest(f_classif, k=min(20000, x_train.shape[1]))\n",
        "    selector.fit(x_train, train_label)\n",
        "    x_train = selector.transform(x_train)\n",
        "    x_val = selector.transform(x_val)\n",
        "\n",
        "    x_train = tf.convert_to_tensor(x_train.todense(), dtype=tf.float32)\n",
        "    x_val = tf.convert_to_tensor(x_val.todense(), dtype=tf.float32)\n",
        "    \n",
        "    return x_train, x_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvolTUxVjqWH"
      },
      "source": [
        "def create_mlp_model():\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(Dropout(rate=0.02, input_shape=(20000,)))\n",
        "  model.add(Dense(units=10000, activation='relu'))\n",
        "  model.add(Dropout(rate=0.02))\n",
        "  model.add(Dense(units=6000, activation='relu'))\n",
        "  model.add(Dropout(rate=0.02))\n",
        "  model.add(Dense(units=6000, activation='relu'))\n",
        "  model.add(Dropout(rate=0.02))\n",
        "  model.add(Dense(units=2000, activation='relu'))\n",
        "  model.add(Dropout(rate=0.02))\n",
        "  model.add(Dense(units=512, activation='relu'))\n",
        "  model.add(Dense(units=256, activation='relu'))\n",
        "  model.add(Dense(units=64, activation='relu'))\n",
        "  model.add(Dropout(rate=0.02))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4f9HTStvlgx"
      },
      "source": [
        "def train_ngram_model(train_data, train_label, learning_rate=1e-3, epochs=1000, batch_size=128):\n",
        "    \n",
        "    (train_data, train_label), (valid_data, valid_label) = split_training_and_validation_sets(train_data, train_label, 0.1)\n",
        "\n",
        "    # Vectorize texts.\n",
        "    x_train, x_val = ngram_vectorizer(train_data, train_label, valid_data)\n",
        "\n",
        "    # Convert Labels to tensor.\n",
        "    train_label = tf.convert_to_tensor(train_label, dtype=tf.float32)\n",
        "    valid_label = tf.convert_to_tensor(valid_label, dtype=tf.float32)\n",
        "    print(train_label)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = create_mlp_model()\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            train_label,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, valid_label),\n",
        "            verbose=2,\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    model.save('/content/gdrive/MyDrive/models/sentiment_analysis_trained_model.h5',save_format= 'tf')\n",
        "    return history['val_acc'][-1], history['val_loss'][-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx7DqYttxQhS",
        "outputId": "95545329-8cb6-4d9a-f99c-011379478419"
      },
      "source": [
        "train_ngram_model(train_data, train_label, learning_rate=1e-3, epochs=1000, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 1. 0. ... 1. 1. 0.], shape=(20250,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "159/159 - 29s - loss: 0.5248 - acc: 0.6876 - val_loss: 1.4293 - val_acc: 0.5107 - 29s/epoch - 183ms/step\n",
            "Epoch 2/1000\n",
            "159/159 - 26s - loss: 0.1485 - acc: 0.9404 - val_loss: 1.5456 - val_acc: 0.5124 - 26s/epoch - 166ms/step\n",
            "Epoch 3/1000\n",
            "159/159 - 27s - loss: 0.0564 - acc: 0.9770 - val_loss: 3.1653 - val_acc: 0.5036 - 27s/epoch - 167ms/step\n",
            "Validation accuracy: 0.5035555362701416, loss: 3.1652894020080566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5035555362701416, 3.1652894020080566)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI-bwlFF4ZwG"
      },
      "source": [
        "Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hooX8_Z94dNy"
      },
      "source": [
        "loaded_model = keras.models.load_model('/content/gdrive/MyDrive/models/sentiment_analysis_trained_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzkvpSP94uSq",
        "outputId": "72f639e9-dabf-4c8d-b59f-33d8ada4ef6b"
      },
      "source": [
        "x_test, _ = ngram_vectorizer(test_data, test_label, valid_data)\n",
        "predictions = loaded_model.predict(x_test)\n",
        "pred = [1 if a>0.5 else 0 for a in predictions]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo36mWTlAmbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab815f8-4d01-4752-ff95-e61af8338760"
      },
      "source": [
        "count = 0\n",
        "for i, j in zip(pred, test_label):\n",
        "  if i==j:\n",
        "    count += 1\n",
        "\n",
        "print(count/len(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49704\n"
          ]
        }
      ]
    }
  ]
}